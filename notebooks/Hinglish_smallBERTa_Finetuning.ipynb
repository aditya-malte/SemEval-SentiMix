{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hinglish_smallBERTa_Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-malte/SemEval/blob/master/notebooks/Hinglish_smallBERTa_Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8KKuFJMknK5",
        "colab_type": "code",
        "outputId": "e5b85490-6abd-459b-f37e-e61d136a6240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "!pip install transformers tensorboardX emoji\n",
        "!pip install pandas tqdm\n",
        "#!python -m spacy download en\n",
        "# !pip install https://download.pytorch.org/whl/cu100/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl && pip install https://download.pytorch.org/whl/cu100/torchvision-0.4.0-cp36-cp36m-manylinux1_x86_64.whl\n",
        "# !git clone https://github.com/NVIDIA/apex # For fp16\n",
        "# !pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/58/3d789b98923da6485f376be1e04d59ad7003a63bdb2b04b5eea7e02857e5/transformers-2.5.0-py3-none-any.whl (481kB)\n",
            "\r\u001b[K     |â–Š                               | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–                              | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆ                              | 30kB 4.2MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–Š                             | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–                            | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆ                            | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 81kB 4.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 491kB 4.9MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\r\u001b[K     |â–ˆâ–Š                              | 10kB 26.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–                            | 20kB 33.5MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 30kB 39.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 40kB 38.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 51kB 24.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 61kB 27.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 71kB 23.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 81kB 20.3MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 92kB 21.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 102kB 20.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 112kB 20.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 122kB 20.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 133kB 20.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 143kB 20.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 153kB 20.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 163kB 20.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 174kB 20.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 184kB 20.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 194kB 20.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 20.8MB/s \n",
            "\u001b[?25hCollecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 10kB 29.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 20kB 38.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 30kB 44.3MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40kB 33.0MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 8.3MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/1d/ea7e2c628942e686595736f73678348272120d026b7acd54fe43e5211bb1/tokenizers-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 21.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 56.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 78.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (45.1.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: emoji, sacremoses\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=787fd05755cd9c9edc0f6723ea2008e265f4d35bab6ae630e38b84bad125c25f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=25c199d86b4137f1199c19b49938b0c03ed5642d6e28f79603186bda8d803b59\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built emoji sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, tensorboardX, emoji\n",
            "Successfully installed emoji-0.5.4 sacremoses-0.0.38 sentencepiece-0.1.85 tensorboardX-2.0 tokenizers-0.5.0 transformers-2.5.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1cB4Nz7Bz_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import getpass\n",
        "import os\n",
        "import time\n",
        "repo_name = \"SemEval\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpyvJAGfTVAb",
        "colab_type": "code",
        "outputId": "56350b9a-6de2-41ae-9510-985e7d5a56fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "if repo_name not in os.listdir():\n",
        "  username = input(\"'User: \")\n",
        "  password = getpass.getpass(prompt='Password: ', stream=None) \n",
        "  os.system(f'git clone https://{username}:{password}@github.com/aditya-malte/{repo_name}.git')\n",
        "  time.sleep(10)\n",
        "%cd {repo_name}\n",
        "from utils_text import PreProcess\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'User: aditya-malte\n",
            "Password: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "/content/SemEval\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjPDNUMiF69D",
        "colab_type": "code",
        "outputId": "e15c913e-341e-4375-9da2-288f414cec96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "!ln -s \"/gdrive/My Drive/SemEval_weights_data\" \"/content/\"\n",
        "drive_path = \"/content/SemEval_weights_data/data/\"\n",
        "\n",
        "try:\n",
        "  os.chdir(drive_path)\n",
        "  #os.chdir('/content/drive/My Drive/Colab Notebooks/semeval')\n",
        "  print('Changed directory')\n",
        "  print(os.getcwd())\n",
        "except:\n",
        "  print('Cannot change directory')\n",
        "  print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /gdrive\n",
            "Changed directory\n",
            "/gdrive/My Drive/SemEval_weights_data/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nLa6_BPG1YP",
        "colab_type": "code",
        "outputId": "a260ea41-3f14-4538-8705-a7247306a6ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import os, re, time\n",
        "import datetime\n",
        "from collections import Counter\n",
        "from os.path import join as joinpath\n",
        "# from tqdm import tqdm\n",
        "# tqdm.pandas()\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/My Drive/SemEval_weights_data/data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0r9Sl15I33M",
        "colab_type": "code",
        "outputId": "19ad7af8-5a30-44e0-db25-7dbd9f5d1830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using:', device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLQGHbU-I4B9",
        "colab_type": "code",
        "outputId": "b1dd9a0d-d0ee-4b62-ba86-9e805e884418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "df_train = pd.read_csv(drive_path+'loaded_train.csv')\n",
        "df_test = pd.read_csv(drive_path+'loaded_val.csv')\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>text</th>\n",
              "      <th>lang_labels</th>\n",
              "      <th>url</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4330</td>\n",
              "      <td>nen Ã¡ vist bolest vztek smutek zmatek osam Ä› l...</td>\n",
              "      <td>Eng O Eng Eng Eng Eng Hin Hin O Eng Eng O Hin ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41616</td>\n",
              "      <td>@nehantics Haan yaar neha ðŸ˜”ðŸ˜” kab karega woh po...</td>\n",
              "      <td>O Hin Hin Hin Hin O Hin Hin Hin Hin EMT Hin Hi...</td>\n",
              "      <td>https://t.co/5RSlSbZNtt</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6648</td>\n",
              "      <td>@RahulGandhi television media congress ke liye...</td>\n",
              "      <td>O Eng Eng Eng Eng Hin Hin Hin Hin O Hin Hin Hi...</td>\n",
              "      <td>https://t.co/HmH8M7PTaK</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2512</td>\n",
              "      <td>@AmitShah @narendramodi All India me nrc lagu ...</td>\n",
              "      <td>O Hin O Hin Hin Hin Eng Hin Hin Hin Eng Hin Hi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>610</td>\n",
              "      <td>@Nehr_who @TypoMantri @anjanaomkashyap Pagal h...</td>\n",
              "      <td>O Eng O Eng O Hin O Hin Hin Hin Hin O Eng Eng ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     uid  ... sentiment\n",
              "0   4330  ...   neutral\n",
              "1  41616  ...   neutral\n",
              "2   6648  ...  negative\n",
              "3   2512  ...  positive\n",
              "4    610  ...   neutral\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdwsj77pIs6Y",
        "colab_type": "code",
        "outputId": "2ad0f827-5cfe-4e4f-e9c7-ec443103f3cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(len(df_train))\n",
        "print(len(df_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14000\n",
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt3_Gn1AHmT2",
        "colab_type": "code",
        "outputId": "eaf2288a-6dd1-4b5d-8bcb-6739bb2a888f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "uid               0\n",
              "text              0\n",
              "lang_labels       0\n",
              "url            7586\n",
              "sentiment         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV0ELWlCHKQD",
        "colab_type": "code",
        "outputId": "44ab2f73-0772-44f8-8d97-718a74f2003f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "uid               0\n",
              "text              0\n",
              "lang_labels       0\n",
              "url            7586\n",
              "sentiment         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGFqbsN183NB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train[df_train['text'].notnull()]\n",
        "df_test = df_test[df_test['text'].notnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSnb25UI4-L3",
        "colab_type": "code",
        "outputId": "42b1ca3c-cf0a-438a-8970-a16d629b7306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "uid               0\n",
              "text              0\n",
              "lang_labels       0\n",
              "url            7586\n",
              "sentiment         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNzN9LzWZA_v",
        "colab_type": "code",
        "outputId": "002377e7-346d-46c6-ddb0-ec24cf90c37a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Counter(df_train.sentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'negative': 4102, 'neutral': 5264, 'positive': 4634})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL1QJqioH699",
        "colab_type": "code",
        "outputId": "814a70f0-f10d-4e04-bb37-fa85302ea683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "preprocess = PreProcess(sep_url=False, remove_url=True, lowercase=True,\n",
        "               convert_emoji=False, solve_gaps=True, remove_punct = True).preprocess\n",
        "\n",
        "df_train[\"text\"] = df_train[\"text\"].apply(preprocess)\n",
        "df_test[\"text\"] = df_test[\"text\"].apply(preprocess)\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>text</th>\n",
              "      <th>lang_labels</th>\n",
              "      <th>url</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4330</td>\n",
              "      <td>nen Ã¡ vist bolest vztek smutek zmatek osam Ä› l...</td>\n",
              "      <td>Eng O Eng Eng Eng Eng Hin Hin O Eng Eng O Hin ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41616</td>\n",
              "      <td>@nehantics haan yaar neha ðŸ˜”ðŸ˜” kab karega woh po...</td>\n",
              "      <td>O Hin Hin Hin Hin O Hin Hin Hin Hin EMT Hin Hi...</td>\n",
              "      <td>https://t.co/5RSlSbZNtt</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6648</td>\n",
              "      <td>@rahulgandhi television media congress ke liye...</td>\n",
              "      <td>O Eng Eng Eng Eng Hin Hin Hin Hin O Hin Hin Hi...</td>\n",
              "      <td>https://t.co/HmH8M7PTaK</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2512</td>\n",
              "      <td>@amitshah @narendramodi all india me nrc lagu ...</td>\n",
              "      <td>O Hin O Hin Hin Hin Eng Hin Hin Hin Eng Hin Hi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>610</td>\n",
              "      <td>@nehr_who @typomantri @anjanaomkashyap pagal h...</td>\n",
              "      <td>O Eng O Eng O Hin O Hin Hin Hin Hin O Eng Eng ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     uid  ... sentiment\n",
              "0   4330  ...   neutral\n",
              "1  41616  ...   neutral\n",
              "2   6648  ...  negative\n",
              "3   2512  ...  positive\n",
              "4    610  ...   neutral\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO0XgfTveYi2",
        "colab_type": "code",
        "outputId": "b7c9960d-54da-4553-81af-852694af9b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "print(df_train[\"text\"].str.len().mean())\n",
        "df_train['length'] = df_train[\"text\"].apply(lambda x: len(x.split()))\n",
        "print(df_train['length'].mean())\n",
        "df_train.boxplot(column=['length'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "108.36557142857143\n",
            "20.202785714285714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f97f7868710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkpQpA1ySMmWAS1Km/g/4ppLgqTWXHAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj9wesOmo_dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# col = 'text'\n",
        "# print(df_test[col].str.len().mean())\n",
        "# df_train['length'] = df_test[col].apply(lambda x: len(x.split()))\n",
        "# print(df_test['length'].mean())\n",
        "# df_test.boxplot(column=['length'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqodiMuWI4GI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_col_names = ['text']\n",
        "# y_col_name = 'sentiment'\n",
        "\n",
        "# split_save_df(df_train, x_col_names=x_col_names, y_col_name=y_col_name,\n",
        "#               output_directory=output_directory, output_format='tsv',\n",
        "#               test_size=0.1, method='random', \n",
        "#               train_name='train.tsv', test_name='val.tsv')\n",
        "\n",
        "save_directory = '/gdrive/My Drive/SemEval_weights_data/data'\n",
        "output_directory = '/tmp'\n",
        "\n",
        "df_train[['text', 'sentiment']].to_csv(joinpath(output_directory, 'train.tsv'), sep='\\t', index=False, header=None)\n",
        "df_test[['text', 'sentiment']].to_csv(joinpath(output_directory, 'dev.tsv'), sep='\\t', index=False, header=None)\n",
        "time.sleep(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucl415GTs3s1",
        "colab_type": "code",
        "outputId": "08d90797-96d0-4e1b-d8fc-ccd3b66a4528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!ls SemEval"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_config.json  notebooks    README.md  utils_text.py\n",
            "__init__.py\t  __pycache__  SemEval\t  XLM_Roberta_Finetuning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVRKcBJVsrZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cd SemEval && git checkout pratik"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C0iTMRMphet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls SemEval/transformer_core"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k6If4dfgFog",
        "colab_type": "text"
      },
      "source": [
        "# XLM ROBERTA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od1teSoFfsUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python run_glue.py --task_name sentimix --model_type xlmroberta --model_name_or_path xlm-roberta-base --data_dir data --output_dir xlm-roberta-base --max_seq_length 64 --per_gpu_train_batch_size 64 --per_gpu_eval_batch_size 64 --num_train_epochs 3 --save_steps 5000 --do_train --do_eval --overwrite_output_dir --fp16\n",
        "\n",
        "## fp32\n",
        "# !python run_glue.py --task_name sentimix --model_type xlmroberta --model_name_or_path xlm-roberta-base --data_dir {DATA_PATH} --output_dir /tmp/sentimix --max_seq_length 64 --per_gpu_train_batch_size 16 --per_gpu_eval_batch_size 32 --logging_steps 100 --num_train_epochs 2 --do_train --do_eval --overwrite_output_dir --evaluate_during_training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87PRDqYcWTMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niRlDxKlgNos",
        "colab_type": "text"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQWAU-1-ZdLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_model_dir = \"/content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uJL5sNqhyiy",
        "colab_type": "code",
        "outputId": "fb4335ee-6472-4f1f-c5f6-f6d998acc254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "cmd = \"python /content/SemEval/transformer_core/run_glue.py --task_name sentimix --model_type roberta --model_name_or_path {pretrained_model_dir} --tokenizer_name {pretrained_model_dir} --config_name {pretrained_model_dir} --data_dir {output_directory} --output_dir {output_directory} --max_seq_length 64 --per_gpu_train_batch_size 64 --per_gpu_eval_batch_size 32 --num_train_epochs 4 --do_train --do_eval --overwrite_output_dir --evaluate_during_training\"\n",
        "print(cmd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python /content/SemEval/transformer_core/run_glue.py --task_name sentimix --model_type roberta --model_name_or_path {pretrained_model_dir} --tokenizer_name {pretrained_model_dir} --config_name {pretrained_model_dir} --data_dir {output_directory} --output_dir {output_directory} --max_seq_length 64 --per_gpu_train_batch_size 64 --per_gpu_eval_batch_size 32 --num_train_epochs 4 --do_train --do_eval --overwrite_output_dir --evaluate_during_training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keiwy1SCkRfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config_path = os.path.join(pretrained_model_dir, \"config.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voMG-YTRiIKZ",
        "colab_type": "code",
        "outputId": "9ed79984-9bd2-404d-eb3c-5fdc9b06b98d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "%cd /content/SemEval/transformer_core/\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SemEval/transformer_core\n",
            "file_utils.py\t    metrics.py\t    __pycache__  runs\n",
            "glue_processors.py  ployglot.ipynb  run_glue.py  utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5wxd7RFgNyx",
        "colab_type": "code",
        "outputId": "dc5ee92b-759e-405f-f509-194777d43965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_glue.py --task_name sentimix --model_type roberta --model_name_or_path {pretrained_model_dir} --tokenizer_name {pretrained_model_dir} --config_name {pretrained_model_dir} --data_dir {output_directory} --output_dir {output_directory} --max_seq_length 288 --per_gpu_train_batch_size 64 --per_gpu_eval_batch_size 32 --num_train_epochs 4 --do_train --do_eval --overwrite_output_dir --evaluate_during_training"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/23/2020 10:51:10 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "02/23/2020 10:51:10 - INFO - transformers.configuration_utils -   loading configuration file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/config.json\n",
            "02/23/2020 10:51:10 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"sentimix\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.3,\n",
            "  \"hidden_size\": 128,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 256,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 288,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 1,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 1,\n",
            "  \"num_labels\": 3,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 10000\n",
            "}\n",
            "\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   Model name '/content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming '/content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   Didn't find file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/added_tokens.json. We won't load it.\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   loading file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/vocab.json\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   loading file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/merges.txt\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   loading file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/special_tokens_map.json\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   loading file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/tokenizer_config.json\n",
            "02/23/2020 10:51:10 - INFO - transformers.modeling_utils -   loading weights file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/pytorch_model.bin\n",
            "02/23/2020 10:51:10 - INFO - transformers.modeling_utils -   Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "02/23/2020 10:51:10 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
            "02/23/2020 10:51:14 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='/content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000', data_dir='/tmp', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=True, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=288, max_steps=-1, model_name_or_path='/content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000', model_type='roberta', n_gpu=1, no_cuda=False, num_train_epochs=4.0, output_dir='/tmp', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=32, per_gpu_train_batch_size=64, save_steps=500, seed=42, server_ip='', server_port='', task_name='sentimix', tokenizer_name='/content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000', warmup_steps=0, weight_decay=0.0)\n",
            "02/23/2020 10:51:14 - INFO - __main__ -   Creating features from dataset file at /tmp\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   Writing example 0/13999\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   guid: train-1\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   input_ids: 0 298 327 318 1890 87 1930 1035 355 261 225 177 258 251 247 177 258 251 247 536 1794 801 2317 225 177 258 251 260 2893 290 1278 436 2041 1767 658 783 703 681 801 2317 1794 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   label: neutral (id = 2)\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   guid: train-2\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   input_ids: 0 298 2148 9739 90 5031 1357 1171 312 463 497 276 357 347 514 1346 720 619 335 942 598 357 2141 598 291 1171 312 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   label: negative (id = 0)\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   guid: train-3\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   input_ids: 0 298 2656 298 939 1925 610 303 274 6503 8530 712 307 458 320 5797 295 1262 712 542 1166 295 5221 1210 1201 654 284 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   label: positive (id = 1)\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   guid: train-4\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   input_ids: 0 298 327 522 67 3714 298 529 84 354 892 373 298 4591 1788 284 398 623 2298 406 345 1131 252 271 2946 1009 7504 1855 366 9365 552 5827 1211 415 284 685 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   label: neutral (id = 2)\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   guid: train-5\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   input_ids: 0 298 939 1309 291 5632 2066 4979 594 4048 475 390 5569 902 411 686 88 4314 548 291 1163 355 4444 305 2111 291 563 88 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   label: positive (id = 1)\n",
            "02/23/2020 10:51:16 - INFO - transformers.data.processors.glue -   Writing example 10000/13999\n",
            "02/23/2020 10:51:17 - INFO - __main__ -   Saving features into cached file /tmp/cached_train_checkpoint-42000_288_sentimix\n",
            "Traceback (most recent call last):\n",
            "  File \"run_glue.py\", line 700, in <module>\n",
            "    main()\n",
            "  File \"run_glue.py\", line 649, in main\n",
            "    global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
            "  File \"run_glue.py\", line 148, in train\n",
            "    optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/optim/optimizer.py\", line 116, in load_state_dict\n",
            "    raise ValueError(\"loaded state dict contains a parameter group \"\n",
            "ValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CRT30TegGqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeSVULUEDjxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python run_glue.py --task_name sentimix --model_type xlmroberta --model_name_or_path xlm-roberta-large --data_dir data --output_dir xlm-roberta-large --max_seq_length 64 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 64 --num_train_epochs 3 --save_steps 5000 --do_train --do_eval --overwrite_output_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1X8HyjMp0u4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python predict.py --task_name sentimix --model_type xlmroberta --model_name_or_path models --data_dir data --output_dir models --max_seq_length 64 --per_gpu_eval_batch_size 128 --do_eval "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76by_uFspmLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIMv7YGR11qB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}