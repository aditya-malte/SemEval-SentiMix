{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hinglish_smallBERTa_Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-malte/SemEval/blob/master/notebooks/Hinglish_smallBERTa_Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8KKuFJMknK5",
        "colab_type": "code",
        "outputId": "e5b85490-6abd-459b-f37e-e61d136a6240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "!pip install transformers tensorboardX emoji\n",
        "!pip install pandas tqdm\n",
        "#!python -m spacy download en\n",
        "# !pip install https://download.pytorch.org/whl/cu100/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl && pip install https://download.pytorch.org/whl/cu100/torchvision-0.4.0-cp36-cp36m-manylinux1_x86_64.whl\n",
        "# !git clone https://github.com/NVIDIA/apex # For fp16\n",
        "# !pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/58/3d789b98923da6485f376be1e04d59ad7003a63bdb2b04b5eea7e02857e5/transformers-2.5.0-py3-none-any.whl (481kB)\n",
            "\r\u001b[K     |▊                               | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 4.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 81kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 491kB 4.9MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 26.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 33.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 39.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 38.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 24.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 23.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 20.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 102kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 112kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 122kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 133kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 194kB 20.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 20.8MB/s \n",
            "\u001b[?25hCollecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 38.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 30kB 44.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 40kB 33.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/1d/ea7e2c628942e686595736f73678348272120d026b7acd54fe43e5211bb1/tokenizers-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 21.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 56.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 78.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (45.1.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: emoji, sacremoses\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=787fd05755cd9c9edc0f6723ea2008e265f4d35bab6ae630e38b84bad125c25f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=25c199d86b4137f1199c19b49938b0c03ed5642d6e28f79603186bda8d803b59\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built emoji sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, tensorboardX, emoji\n",
            "Successfully installed emoji-0.5.4 sacremoses-0.0.38 sentencepiece-0.1.85 tensorboardX-2.0 tokenizers-0.5.0 transformers-2.5.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1cB4Nz7Bz_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import getpass\n",
        "import os\n",
        "import time\n",
        "repo_name = \"SemEval\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpyvJAGfTVAb",
        "colab_type": "code",
        "outputId": "56350b9a-6de2-41ae-9510-985e7d5a56fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "if repo_name not in os.listdir():\n",
        "  username = input(\"'User: \")\n",
        "  password = getpass.getpass(prompt='Password: ', stream=None) \n",
        "  os.system(f'git clone https://{username}:{password}@github.com/aditya-malte/{repo_name}.git')\n",
        "  time.sleep(10)\n",
        "%cd {repo_name}\n",
        "from utils_text import PreProcess\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'User: aditya-malte\n",
            "Password: ··········\n",
            "/content/SemEval\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjPDNUMiF69D",
        "colab_type": "code",
        "outputId": "e15c913e-341e-4375-9da2-288f414cec96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "!ln -s \"/gdrive/My Drive/SemEval_weights_data\" \"/content/\"\n",
        "drive_path = \"/content/SemEval_weights_data/data/\"\n",
        "\n",
        "try:\n",
        "  os.chdir(drive_path)\n",
        "  #os.chdir('/content/drive/My Drive/Colab Notebooks/semeval')\n",
        "  print('Changed directory')\n",
        "  print(os.getcwd())\n",
        "except:\n",
        "  print('Cannot change directory')\n",
        "  print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "Changed directory\n",
            "/gdrive/My Drive/SemEval_weights_data/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nLa6_BPG1YP",
        "colab_type": "code",
        "outputId": "a260ea41-3f14-4538-8705-a7247306a6ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import os, re, time\n",
        "import datetime\n",
        "from collections import Counter\n",
        "from os.path import join as joinpath\n",
        "# from tqdm import tqdm\n",
        "# tqdm.pandas()\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/My Drive/SemEval_weights_data/data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0r9Sl15I33M",
        "colab_type": "code",
        "outputId": "19ad7af8-5a30-44e0-db25-7dbd9f5d1830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using:', device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLQGHbU-I4B9",
        "colab_type": "code",
        "outputId": "b1dd9a0d-d0ee-4b62-ba86-9e805e884418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "df_train = pd.read_csv(drive_path+'loaded_train.csv')\n",
        "df_test = pd.read_csv(drive_path+'loaded_val.csv')\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>text</th>\n",
              "      <th>lang_labels</th>\n",
              "      <th>url</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4330</td>\n",
              "      <td>nen á vist bolest vztek smutek zmatek osam ě l...</td>\n",
              "      <td>Eng O Eng Eng Eng Eng Hin Hin O Eng Eng O Hin ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41616</td>\n",
              "      <td>@nehantics Haan yaar neha 😔😔 kab karega woh po...</td>\n",
              "      <td>O Hin Hin Hin Hin O Hin Hin Hin Hin EMT Hin Hi...</td>\n",
              "      <td>https://t.co/5RSlSbZNtt</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6648</td>\n",
              "      <td>@RahulGandhi television media congress ke liye...</td>\n",
              "      <td>O Eng Eng Eng Eng Hin Hin Hin Hin O Hin Hin Hi...</td>\n",
              "      <td>https://t.co/HmH8M7PTaK</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2512</td>\n",
              "      <td>@AmitShah @narendramodi All India me nrc lagu ...</td>\n",
              "      <td>O Hin O Hin Hin Hin Eng Hin Hin Hin Eng Hin Hi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>610</td>\n",
              "      <td>@Nehr_who @TypoMantri @anjanaomkashyap Pagal h...</td>\n",
              "      <td>O Eng O Eng O Hin O Hin Hin Hin Hin O Eng Eng ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     uid  ... sentiment\n",
              "0   4330  ...   neutral\n",
              "1  41616  ...   neutral\n",
              "2   6648  ...  negative\n",
              "3   2512  ...  positive\n",
              "4    610  ...   neutral\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdwsj77pIs6Y",
        "colab_type": "code",
        "outputId": "2ad0f827-5cfe-4e4f-e9c7-ec443103f3cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(len(df_train))\n",
        "print(len(df_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14000\n",
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt3_Gn1AHmT2",
        "colab_type": "code",
        "outputId": "eaf2288a-6dd1-4b5d-8bcb-6739bb2a888f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "uid               0\n",
              "text              0\n",
              "lang_labels       0\n",
              "url            7586\n",
              "sentiment         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV0ELWlCHKQD",
        "colab_type": "code",
        "outputId": "44ab2f73-0772-44f8-8d97-718a74f2003f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "uid               0\n",
              "text              0\n",
              "lang_labels       0\n",
              "url            7586\n",
              "sentiment         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGFqbsN183NB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train[df_train['text'].notnull()]\n",
        "df_test = df_test[df_test['text'].notnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSnb25UI4-L3",
        "colab_type": "code",
        "outputId": "42b1ca3c-cf0a-438a-8970-a16d629b7306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "uid               0\n",
              "text              0\n",
              "lang_labels       0\n",
              "url            7586\n",
              "sentiment         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNzN9LzWZA_v",
        "colab_type": "code",
        "outputId": "002377e7-346d-46c6-ddb0-ec24cf90c37a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Counter(df_train.sentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'negative': 4102, 'neutral': 5264, 'positive': 4634})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL1QJqioH699",
        "colab_type": "code",
        "outputId": "814a70f0-f10d-4e04-bb37-fa85302ea683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "preprocess = PreProcess(sep_url=False, remove_url=True, lowercase=True,\n",
        "               convert_emoji=False, solve_gaps=True, remove_punct = True).preprocess\n",
        "\n",
        "df_train[\"text\"] = df_train[\"text\"].apply(preprocess)\n",
        "df_test[\"text\"] = df_test[\"text\"].apply(preprocess)\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>text</th>\n",
              "      <th>lang_labels</th>\n",
              "      <th>url</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4330</td>\n",
              "      <td>nen á vist bolest vztek smutek zmatek osam ě l...</td>\n",
              "      <td>Eng O Eng Eng Eng Eng Hin Hin O Eng Eng O Hin ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41616</td>\n",
              "      <td>@nehantics haan yaar neha 😔😔 kab karega woh po...</td>\n",
              "      <td>O Hin Hin Hin Hin O Hin Hin Hin Hin EMT Hin Hi...</td>\n",
              "      <td>https://t.co/5RSlSbZNtt</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6648</td>\n",
              "      <td>@rahulgandhi television media congress ke liye...</td>\n",
              "      <td>O Eng Eng Eng Eng Hin Hin Hin Hin O Hin Hin Hi...</td>\n",
              "      <td>https://t.co/HmH8M7PTaK</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2512</td>\n",
              "      <td>@amitshah @narendramodi all india me nrc lagu ...</td>\n",
              "      <td>O Hin O Hin Hin Hin Eng Hin Hin Hin Eng Hin Hi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>610</td>\n",
              "      <td>@nehr_who @typomantri @anjanaomkashyap pagal h...</td>\n",
              "      <td>O Eng O Eng O Hin O Hin Hin Hin Hin O Eng Eng ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     uid  ... sentiment\n",
              "0   4330  ...   neutral\n",
              "1  41616  ...   neutral\n",
              "2   6648  ...  negative\n",
              "3   2512  ...  positive\n",
              "4    610  ...   neutral\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO0XgfTveYi2",
        "colab_type": "code",
        "outputId": "b7c9960d-54da-4553-81af-852694af9b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "print(df_train[\"text\"].str.len().mean())\n",
        "df_train['length'] = df_train[\"text\"].apply(lambda x: len(x.split()))\n",
        "print(df_train['length'].mean())\n",
        "df_train.boxplot(column=['length'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "108.36557142857143\n",
            "20.202785714285714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f97f7868710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkpQpA1ySMmWAS1Km/g/4ppLgqTWXHAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj9wesOmo_dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# col = 'text'\n",
        "# print(df_test[col].str.len().mean())\n",
        "# df_train['length'] = df_test[col].apply(lambda x: len(x.split()))\n",
        "# print(df_test['length'].mean())\n",
        "# df_test.boxplot(column=['length'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqodiMuWI4GI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_col_names = ['text']\n",
        "# y_col_name = 'sentiment'\n",
        "\n",
        "# split_save_df(df_train, x_col_names=x_col_names, y_col_name=y_col_name,\n",
        "#               output_directory=output_directory, output_format='tsv',\n",
        "#               test_size=0.1, method='random', \n",
        "#               train_name='train.tsv', test_name='val.tsv')\n",
        "\n",
        "save_directory = '/gdrive/My Drive/SemEval_weights_data/data'\n",
        "output_directory = '/tmp'\n",
        "\n",
        "df_train[['text', 'sentiment']].to_csv(joinpath(output_directory, 'train.tsv'), sep='\\t', index=False, header=None)\n",
        "df_test[['text', 'sentiment']].to_csv(joinpath(output_directory, 'dev.tsv'), sep='\\t', index=False, header=None)\n",
        "time.sleep(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucl415GTs3s1",
        "colab_type": "code",
        "outputId": "08d90797-96d0-4e1b-d8fc-ccd3b66a4528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!ls SemEval"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_config.json  notebooks    README.md  utils_text.py\n",
            "__init__.py\t  __pycache__  SemEval\t  XLM_Roberta_Finetuning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVRKcBJVsrZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cd SemEval && git checkout pratik"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C0iTMRMphet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls SemEval/transformer_core"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k6If4dfgFog",
        "colab_type": "text"
      },
      "source": [
        "# XLM ROBERTA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od1teSoFfsUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python run_glue.py --task_name sentimix --model_type xlmroberta --model_name_or_path xlm-roberta-base --data_dir data --output_dir xlm-roberta-base --max_seq_length 64 --per_gpu_train_batch_size 64 --per_gpu_eval_batch_size 64 --num_train_epochs 3 --save_steps 5000 --do_train --do_eval --overwrite_output_dir --fp16\n",
        "\n",
        "## fp32\n",
        "# !python run_glue.py --task_name sentimix --model_type xlmroberta --model_name_or_path xlm-roberta-base --data_dir {DATA_PATH} --output_dir /tmp/sentimix --max_seq_length 64 --per_gpu_train_batch_size 16 --per_gpu_eval_batch_size 32 --logging_steps 100 --num_train_epochs 2 --do_train --do_eval --overwrite_output_dir --evaluate_during_training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87PRDqYcWTMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niRlDxKlgNos",
        "colab_type": "text"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQWAU-1-ZdLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_model_dir = \"/content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uJL5sNqhyiy",
        "colab_type": "code",
        "outputId": "fb4335ee-6472-4f1f-c5f6-f6d998acc254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "cmd = \"python /content/SemEval/transformer_core/run_glue.py --task_name sentimix --model_type roberta --model_name_or_path {pretrained_model_dir} --tokenizer_name {pretrained_model_dir} --config_name {pretrained_model_dir} --data_dir {output_directory} --output_dir {output_directory} --max_seq_length 64 --per_gpu_train_batch_size 64 --per_gpu_eval_batch_size 32 --num_train_epochs 4 --do_train --do_eval --overwrite_output_dir --evaluate_during_training\"\n",
        "print(cmd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python /content/SemEval/transformer_core/run_glue.py --task_name sentimix --model_type roberta --model_name_or_path {pretrained_model_dir} --tokenizer_name {pretrained_model_dir} --config_name {pretrained_model_dir} --data_dir {output_directory} --output_dir {output_directory} --max_seq_length 64 --per_gpu_train_batch_size 64 --per_gpu_eval_batch_size 32 --num_train_epochs 4 --do_train --do_eval --overwrite_output_dir --evaluate_during_training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keiwy1SCkRfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config_path = os.path.join(pretrained_model_dir, \"config.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voMG-YTRiIKZ",
        "colab_type": "code",
        "outputId": "9ed79984-9bd2-404d-eb3c-5fdc9b06b98d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "%cd /content/SemEval/transformer_core/\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SemEval/transformer_core\n",
            "file_utils.py\t    metrics.py\t    __pycache__  runs\n",
            "glue_processors.py  ployglot.ipynb  run_glue.py  utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5wxd7RFgNyx",
        "colab_type": "code",
        "outputId": "dc5ee92b-759e-405f-f509-194777d43965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_glue.py --task_name sentimix --model_type roberta --model_name_or_path {pretrained_model_dir} --tokenizer_name {pretrained_model_dir} --config_name {pretrained_model_dir} --data_dir {output_directory} --output_dir {output_directory} --max_seq_length 288 --per_gpu_train_batch_size 64 --per_gpu_eval_batch_size 32 --num_train_epochs 4 --do_train --do_eval --overwrite_output_dir --evaluate_during_training"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/23/2020 10:51:10 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "02/23/2020 10:51:10 - INFO - transformers.configuration_utils -   loading configuration file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/config.json\n",
            "02/23/2020 10:51:10 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"sentimix\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.3,\n",
            "  \"hidden_size\": 128,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 256,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 288,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 1,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 1,\n",
            "  \"num_labels\": 3,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 10000\n",
            "}\n",
            "\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   Model name '/content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming '/content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   Didn't find file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/added_tokens.json. We won't load it.\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   loading file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/vocab.json\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   loading file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/merges.txt\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   loading file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/special_tokens_map.json\n",
            "02/23/2020 10:51:10 - INFO - transformers.tokenization_utils -   loading file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/tokenizer_config.json\n",
            "02/23/2020 10:51:10 - INFO - transformers.modeling_utils -   loading weights file /content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000/pytorch_model.bin\n",
            "02/23/2020 10:51:10 - INFO - transformers.modeling_utils -   Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "02/23/2020 10:51:10 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
            "02/23/2020 10:51:14 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='/content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000', data_dir='/tmp', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=True, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=288, max_steps=-1, model_name_or_path='/content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000', model_type='roberta', n_gpu=1, no_cuda=False, num_train_epochs=4.0, output_dir='/tmp', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=32, per_gpu_train_batch_size=64, save_steps=500, seed=42, server_ip='', server_port='', task_name='sentimix', tokenizer_name='/content/SemEval_weights_data/Hinglish_smallBERTa/smallBERTa/weights/checkpoint-42000', warmup_steps=0, weight_decay=0.0)\n",
            "02/23/2020 10:51:14 - INFO - __main__ -   Creating features from dataset file at /tmp\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   Writing example 0/13999\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   guid: train-1\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   input_ids: 0 298 327 318 1890 87 1930 1035 355 261 225 177 258 251 247 177 258 251 247 536 1794 801 2317 225 177 258 251 260 2893 290 1278 436 2041 1767 658 783 703 681 801 2317 1794 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   label: neutral (id = 2)\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   guid: train-2\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   input_ids: 0 298 2148 9739 90 5031 1357 1171 312 463 497 276 357 347 514 1346 720 619 335 942 598 357 2141 598 291 1171 312 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   label: negative (id = 0)\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   guid: train-3\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   input_ids: 0 298 2656 298 939 1925 610 303 274 6503 8530 712 307 458 320 5797 295 1262 712 542 1166 295 5221 1210 1201 654 284 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   label: positive (id = 1)\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   guid: train-4\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   input_ids: 0 298 327 522 67 3714 298 529 84 354 892 373 298 4591 1788 284 398 623 2298 406 345 1131 252 271 2946 1009 7504 1855 366 9365 552 5827 1211 415 284 685 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   label: neutral (id = 2)\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   guid: train-5\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   input_ids: 0 298 939 1309 291 5632 2066 4979 594 4048 475 390 5569 902 411 686 88 4314 548 291 1163 355 4444 305 2111 291 563 88 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "02/23/2020 10:51:14 - INFO - transformers.data.processors.glue -   label: positive (id = 1)\n",
            "02/23/2020 10:51:16 - INFO - transformers.data.processors.glue -   Writing example 10000/13999\n",
            "02/23/2020 10:51:17 - INFO - __main__ -   Saving features into cached file /tmp/cached_train_checkpoint-42000_288_sentimix\n",
            "Traceback (most recent call last):\n",
            "  File \"run_glue.py\", line 700, in <module>\n",
            "    main()\n",
            "  File \"run_glue.py\", line 649, in main\n",
            "    global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
            "  File \"run_glue.py\", line 148, in train\n",
            "    optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/optim/optimizer.py\", line 116, in load_state_dict\n",
            "    raise ValueError(\"loaded state dict contains a parameter group \"\n",
            "ValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CRT30TegGqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeSVULUEDjxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python run_glue.py --task_name sentimix --model_type xlmroberta --model_name_or_path xlm-roberta-large --data_dir data --output_dir xlm-roberta-large --max_seq_length 64 --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 64 --num_train_epochs 3 --save_steps 5000 --do_train --do_eval --overwrite_output_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1X8HyjMp0u4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python predict.py --task_name sentimix --model_type xlmroberta --model_name_or_path models --data_dir data --output_dir models --max_seq_length 64 --per_gpu_eval_batch_size 128 --do_eval "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76by_uFspmLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIMv7YGR11qB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}