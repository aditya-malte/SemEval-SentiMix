{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hinglish_smallBERTa_Pretraining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTXDoUS6XzANDuDl1XMaHJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-malte/SemEval/blob/master/notebooks/Hinglish_smallBERTa_Pretraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4OynugZvMG2",
        "colab_type": "text"
      },
      "source": [
        "# Pre-training SmallBERTa - A tiny model to train on a tiny dataset\n",
        "(Using HuggingFace Transformers)<br>\n",
        "Admittedly, while language modeling is associated with terabytes of data, not all of use have either the processing power nor the resources to train huge models on such huge amounts of data.\n",
        "In this example, we are going to train a relatively small neural net on a small dataset (which still happens to have over 2M rows).\n",
        "<br>\n",
        "\n",
        "The ***main purpose*** of this blog is not to achieve state-of-the-art performance on LM tasks but to show a simple idea of how the recent language_modeling.py script can be used to train a Transformer model from scratch.\n",
        "\n",
        "This very notebook can be extended to various esoteric use cases where general purpose pre-trained models fail to perform well. Examples include medical dataset, scientific literature, legal documentation, etc.\n",
        "\n",
        "Input:\n",
        "  1. To the Tokenizer:<br>\n",
        "      LM data in a directory containing all samples in separate *.txt files.\n",
        "  \n",
        "  2. To the Model:<br>\n",
        "      LM data split into:<br>\n",
        "        1. train.txt <br>\n",
        "        2. eval.txt \n",
        "        \n",
        "Output:<br>\n",
        "  Trained Model weights(that can be used elsewhere) and Tensorboard logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sHQ_tWig474",
        "colab_type": "text"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPxoElNugaMu",
        "colab_type": "code",
        "outputId": "82578acc-6738-4ac5-ee2f-35b71303a0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#tokenizer working version --- 0.5.0\n",
        "#transformer working version --- 2.5.0\n",
        "!pip install transformers\n",
        "!pip install tokenizers\n",
        "!pip install emoji\n",
        "!pip install tensorboard==2.1.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/58/3d789b98923da6485f376be1e04d59ad7003a63bdb2b04b5eea7e02857e5/transformers-2.5.0-py3-none-any.whl (481kB)\n",
            "\r\u001b[K     |▊                               | 10kB 26.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 6.0MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 6.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 5.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 6.0MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 7.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 71kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 81kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 112kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 122kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 133kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 143kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 153kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 163kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 174kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 184kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 204kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 215kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 225kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 235kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 245kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 256kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 266kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 276kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 286kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 296kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 307kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 317kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 327kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 337kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 348kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 358kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 368kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 378kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 389kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 399kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 409kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 419kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 430kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 440kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 450kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 460kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 471kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 491kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 20.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 48.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Collecting tokenizers==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/1d/ea7e2c628942e686595736f73678348272120d026b7acd54fe43e5211bb1/tokenizers-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 54.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=ca16d748679e11daa1fd51901763871c775c6a30c4f8c616ef46b506aa7f3754\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.0 transformers-2.5.0\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=6b9a6013bb0c7461c2ef9ce3f457a55caf09a05fa32d4ec01aade89fc1247e7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n",
            "Collecting tensorboard==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 86kB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0) (1.17.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0) (1.27.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0) (45.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.1.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard==2.1.0) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard==2.1.0) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr18wdkbLEsx",
        "colab_type": "code",
        "outputId": "214cf51e-770d-40e8-9af5-453406aa3320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "from requests.utils import quote\n",
        "import getpass\n",
        "repo_name = \"SemEval\"\n",
        "if repo_name not in os.listdir():\n",
        "  username = input(\"User: \")\n",
        "  password = getpass.getpass(prompt='Password: ') \n",
        "  print(os.system(\"git clone https://\"+username+\":\"+password+\"@github.com/aditya-malte/\"+repo_name+\".git\"))\n",
        "%cd {repo_name}\n",
        "from utils_text import PreProcess\n",
        "%cd ..\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User: aditya-malte\n",
            "Password: ··········\n",
            "0\n",
            "/content/SemEval\n",
            "/content\n",
            "sample_data  SemEval\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoFuhUGvLMD5",
        "colab_type": "code",
        "outputId": "08dcf22e-e7bc-4a97-c29c-32367c90f882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "!ln -s \"/gdrive/My Drive/SemEval_weights_data\" \"/content/\"\n",
        "drive_path = \"/content/SemEval_weights_data/data/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBcbCQoEg9cT",
        "colab_type": "text"
      },
      "source": [
        "## Fetch Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtFnApKwiGUb",
        "colab_type": "code",
        "outputId": "4a36e741-ea5a-4b5f-b6db-8a5d00757abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "source": [
        "import pandas as pd\n",
        "text_mixed =pd.read_csv(\"/content/SemEval_weights_data/twitter_scraped/tweets_final_mix_394468.csv\", lineterminator='\\n')\n",
        "text_mixed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Meri Kashti Nu Dar Kahda Toofan Da \\nMai Gadha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Yahaan choor ko jaza or Ghareeb ko Saza milti ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Date Pakri Gai In Village: http://youtu.be/ddL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Bhai tu smjha hi nahin ab tak ki aj baarish bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Zindagi Ki BheeK To Kisi Sourat ManGi Na Gahi,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394463</th>\n",
              "      <td>37281</td>\n",
              "      <td>मस्जिद इस्लाम का अंग है या नहीं, इस पर बहस हो ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394464</th>\n",
              "      <td>37282</td>\n",
              "      <td>Bhi aap great ho or Mara sval ya ha ki aap har...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394465</th>\n",
              "      <td>37284</td>\n",
              "      <td>तुम पास रहो,\\nये ज़िद तो नहीं,\\nपर किसी लंबे स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394466</th>\n",
              "      <td>37285</td>\n",
              "      <td>केवल आम आदमी पार्टी ही है जो देश निर्माण का का...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394467</th>\n",
              "      <td>37286</td>\n",
              "      <td>hahahah nahi jee an ko ab bhol jao yeh kabhi l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>394468 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0                                             tweets\n",
              "0                0  Meri Kashti Nu Dar Kahda Toofan Da \\nMai Gadha...\n",
              "1                1  Yahaan choor ko jaza or Ghareeb ko Saza milti ...\n",
              "2                2  Date Pakri Gai In Village: http://youtu.be/ddL...\n",
              "3                3  Bhai tu smjha hi nahin ab tak ki aj baarish bo...\n",
              "4                4  Zindagi Ki BheeK To Kisi Sourat ManGi Na Gahi,...\n",
              "...            ...                                                ...\n",
              "394463       37281  मस्जिद इस्लाम का अंग है या नहीं, इस पर बहस हो ...\n",
              "394464       37282  Bhi aap great ho or Mara sval ya ha ki aap har...\n",
              "394465       37284  तुम पास रहो,\\nये ज़िद तो नहीं,\\nपर किसी लंबे स...\n",
              "394466       37285  केवल आम आदमी पार्टी ही है जो देश निर्माण का का...\n",
              "394467       37286  hahahah nahi jee an ko ab bhol jao yeh kabhi l...\n",
              "\n",
              "[394468 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ7hj9kuhBIj",
        "colab_type": "text"
      },
      "source": [
        "## Load and Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn68O17MsqYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-bgANE9LS64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def getHindi(input_list):\n",
        "  regex = \"[\\u0900-\\u097F]\"\n",
        "  output_list = []\n",
        "  for test_text in input_list:\n",
        "      try:\n",
        "        match = re.search(regex, test_text)\n",
        "        if match is None:\n",
        "          output_list.append(test_text)\n",
        "      except Exception as e:\n",
        "        print(e, test_text)\n",
        "  return output_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl0M7fddLiZQ",
        "colab_type": "code",
        "outputId": "11cd5821-a6ea-4da6-b470-0e4fda8dd9d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "text_pure = pd.DataFrame(getHindi(text_mixed[\"tweets\"].tolist()), columns=[\"tweets\"])\n",
        "text_pure.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "expected string or bytes-like object nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Meri Kashti Nu Dar Kahda Toofan Da \\nMai Gadha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yahaan choor ko jaza or Ghareeb ko Saza milti ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Date Pakri Gai In Village: http://youtu.be/ddL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bhai tu smjha hi nahin ab tak ki aj baarish bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Zindagi Ki BheeK To Kisi Sourat ManGi Na Gahi,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets\n",
              "0  Meri Kashti Nu Dar Kahda Toofan Da \\nMai Gadha...\n",
              "1  Yahaan choor ko jaza or Ghareeb ko Saza milti ...\n",
              "2  Date Pakri Gai In Village: http://youtu.be/ddL...\n",
              "3  Bhai tu smjha hi nahin ab tak ki aj baarish bo...\n",
              "4  Zindagi Ki BheeK To Kisi Sourat ManGi Na Gahi,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYYUOhiXhHP8",
        "colab_type": "text"
      },
      "source": [
        "### Before Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8STrareTIxox",
        "colab_type": "code",
        "outputId": "4296beaa-54c1-4118-b8a4-543b54091e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "text_pure = text_pure.sample(frac=1).sample(frac=1).sample(frac=1)\n",
        "print(text_pure)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   tweets\n",
            "67228   Bin mausam ki baarish ya toh kuch leke jaati h...\n",
            "106616  Dimag kharab hai is neta ka kashmir ko aazadi ...\n",
            "121984  Har Muskrahat k Baad\\nKhuda Ka Shukar Adaa Nhi...\n",
            "295484  Haaa ye to h per dhawan ke wicket ke baad jo n...\n",
            "235611  I agree.\\nAisay khail rahay thay jaisay vacati...\n",
            "...                                                   ...\n",
            "135660  Manyavar pm modi va yogi sharkar mahngai rokan...\n",
            "95900   @9919Shivam ek baar ek Hindu or Muslim dono me...\n",
            "296401  Seekh nahi Kaan ke neeche bajana chahiye tha u...\n",
            "206865  Modi ji aap toh janam se hi fakiri hai aap me....\n",
            "38972   Ranji Trophy 2015-16: Mohammad Kaif, Ricky Bhu...\n",
            "\n",
            "[306259 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdJCJBmkLkxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocess = PreProcess(sep_url=False, remove_url=True, lowercase=True,\n",
        "               convert_emoji=False, solve_gaps=True, remove_punct = True).preprocess\n",
        "\n",
        "data = pd.DataFrame(text_pure[\"tweets\"].apply(preprocess).dropna(), columns=[\"tweets\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCzsk_sVhLsi",
        "colab_type": "text"
      },
      "source": [
        "### After Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV8ysU3cI1a-",
        "colab_type": "code",
        "outputId": "6af687bc-5eb8-4024-d716-e600914b43e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   tweets\n",
            "67228   bin mausam ki baarish ya toh kuch leke jaati h...\n",
            "106616  dimag kharab hai is neta ka kashmir ko aazadi ...\n",
            "121984  har muskrahat k baad khuda ka shukar adaa nhi ...\n",
            "295484  haaa ye to h per dhawan ke wicket ke baad jo n...\n",
            "235611  i agree. aisay khail rahay thay jaisay vacatio...\n",
            "...                                                   ...\n",
            "135660  manyavar pm modi va yogi sharkar mahngai rokan...\n",
            "95900   @shivam ek baar ek hindu or muslim dono me bho...\n",
            "296401  seekh nahi kaan ke neeche bajana chahiye tha u...\n",
            "206865  modi ji aap toh janam se hi fakiri hai aap me....\n",
            "38972   ranji trophy -: mohammad kaif, ricky bhui shin...\n",
            "\n",
            "[306259 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbp40Xkrhs8l",
        "colab_type": "text"
      },
      "source": [
        "Removing newline characters just in case the input text has them. This is because the LineByLine class that we are going to use later assumes that samples are separated by newline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dBFTDQnjXnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[\"tweets\"]\n",
        "data = data.replace(\"\\n\",\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI1Tp54IiVBj",
        "colab_type": "text"
      },
      "source": [
        "## Train a custom tokenizer\n",
        "I have used a ByteLevelBPETokenizer just to prevent \\<unk> tokens entirely.\n",
        "Furthermore, the function used to train the tokenizer assumes that each sample is stored in a different text file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs-wK-N1EACp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txt_files_dir = \"/tmp/text_split\"\n",
        "!mkdir {txt_files_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIvCE_svi7sQ",
        "colab_type": "text"
      },
      "source": [
        "Split LM data into individual files. These files are stored in /tmp/text_split and are used to train the tokenizer **only**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2oI92Z0tyAp",
        "colab_type": "code",
        "outputId": "b064681c-c87c-429d-c528-44f58e95351c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "i=0\n",
        "for row in tqdm(data.to_list()):\n",
        "  file_name = os.path.join(txt_files_dir, str(i)+'.txt')\n",
        "  try:\n",
        "    f = open(file_name, 'w')\n",
        "    f.write(row)\n",
        "    f.close()\n",
        "  except Exception as e:  #catch exceptions(for eg. empty rows)\n",
        "    print(row, e) \n",
        "  i+=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 306259/306259 [00:14<00:00, 21764.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r6RuiCBXIJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "\n",
        "paths = [str(x) for x in Path(txt_files_dir).glob(\"**/*.txt\")]\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "vocab_size=20000\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=vocab_size, min_frequency=5, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bv78Z2UjIci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm_data_dir = \"/tmp/lm_data\"\n",
        "!mkdir {lm_data_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI5kEwUojOQo",
        "colab_type": "text"
      },
      "source": [
        "## Split into Valdation and Train set\n",
        "We split the train data into validation and train. These two files are used to train and evaluate our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nWv7Yuki66k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_split = 0.9\n",
        "train_data_size = int(len(data)*train_split)\n",
        "\n",
        "with open(os.path.join(lm_data_dir,'train.txt') , 'w') as f:\n",
        "    for item in data[:train_data_size].tolist():\n",
        "        f.write(\"%s\\n\" % item)\n",
        "\n",
        "with open(os.path.join(lm_data_dir,'eval.txt') , 'w') as f:\n",
        "    for item in data[train_data_size:].tolist():\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKaVWBiVTtEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/models\n",
        "!mkdir /content/models/smallBERTa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noQfBUkhJmFC",
        "colab_type": "code",
        "outputId": "49674e27-bd0b-4cff-fc10-7dea31db37e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "tokenizer.save(\"/content/models/smallBERTa\", \"smallBERTa\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/models/smallBERTa/smallBERTa-vocab.json',\n",
              " '/content/models/smallBERTa/smallBERTa-merges.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odSTiCM--4_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/models/smallBERTa/smallBERTa-vocab.json /content/models/smallBERTa/vocab.json\n",
        "!mv /content/models/smallBERTa/smallBERTa-merges.txt /content/models/smallBERTa/merges.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naEJbZDjFnNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = os.path.join(lm_data_dir,\"train.txt\")\n",
        "eval_path = os.path.join(lm_data_dir,\"eval.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P91yVQkXj9rc",
        "colab_type": "text"
      },
      "source": [
        "## Set Model Configuration\n",
        "For our purpose, we are training a very small model for demo purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS4q1YtxZ2GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "config = {\n",
        "  \"attention_probs_dropout_prob\": 0.1,\n",
        "  \"hidden_act\": \"gelu\",\n",
        "  \"hidden_dropout_prob\": 0.3,\n",
        "  \"hidden_size\": 128,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"num_attention_heads\": 1,\n",
        "  \"num_hidden_layers\": 1,\n",
        "  \"vocab_size\": vocab_size,\n",
        "  \"intermediate_size\": 256,\n",
        "  \"max_position_embeddings\": 288\n",
        "}\n",
        "with open(\"/content/models/smallBERTa/config.json\", 'w') as fp:\n",
        "    json.dump(config, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CbVBgrDbmVJ2",
        "outputId": "fa355c8c-262e-4be5-844d-7262b11f8bf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "#%cd /content\n",
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/52)\u001b[K\rremote: Counting objects:   3% (2/52)\u001b[K\rremote: Counting objects:   5% (3/52)\u001b[K\rremote: Counting objects:   7% (4/52)\u001b[K\rremote: Counting objects:   9% (5/52)\u001b[K\rremote: Counting objects:  11% (6/52)\u001b[K\rremote: Counting objects:  13% (7/52)\u001b[K\rremote: Counting objects:  15% (8/52)\u001b[K\rremote: Counting objects:  17% (9/52)\u001b[K\rremote: Counting objects:  19% (10/52)\u001b[K\rremote: Counting objects:  21% (11/52)\u001b[K\rremote: Counting objects:  23% (12/52)\u001b[K\rremote: Counting objects:  25% (13/52)\u001b[K\rremote: Counting objects:  26% (14/52)\u001b[K\rremote: Counting objects:  28% (15/52)\u001b[K\rremote: Counting objects:  30% (16/52)\u001b[K\rremote: Counting objects:  32% (17/52)\u001b[K\rremote: Counting objects:  34% (18/52)\u001b[K\rremote: Counting objects:  36% (19/52)\u001b[K\rremote: Counting objects:  38% (20/52)\u001b[K\rremote: Counting objects:  40% (21/52)\u001b[K\rremote: Counting objects:  42% (22/52)\u001b[K\rremote: Counting objects:  44% (23/52)\u001b[K\rremote: Counting objects:  46% (24/52)\u001b[K\rremote: Counting objects:  48% (25/52)\u001b[K\rremote: Counting objects:  50% (26/52)\u001b[K\rremote: Counting objects:  51% (27/52)\u001b[K\rremote: Counting objects:  53% (28/52)\u001b[K\rremote: Counting objects:  55% (29/52)\u001b[K\rremote: Counting objects:  57% (30/52)\u001b[K\rremote: Counting objects:  59% (31/52)\u001b[K\rremote: Counting objects:  61% (32/52)\u001b[K\rremote: Counting objects:  63% (33/52)\u001b[K\rremote: Counting objects:  65% (34/52)\u001b[K\rremote: Counting objects:  67% (35/52)\u001b[K\rremote: Counting objects:  69% (36/52)\u001b[K\rremote: Counting objects:  71% (37/52)\u001b[K\rremote: Counting objects:  73% (38/52)\u001b[K\rremote: Counting objects:  75% (39/52)\u001b[K\rremote: Counting objects:  76% (40/52)\u001b[K\rremote: Counting objects:  78% (41/52)\u001b[K\rremote: Counting objects:  80% (42/52)\u001b[K\rremote: Counting objects:  82% (43/52)\u001b[K\rremote: Counting objects:  84% (44/52)\u001b[K\rremote: Counting objects:  86% (45/52)\u001b[K\rremote: Counting objects:  88% (46/52)\u001b[K\rremote: Counting objects:  90% (47/52)\u001b[K\rremote: Counting objects:  92% (48/52)\u001b[K\rremote: Counting objects:  94% (49/52)\u001b[K\rremote: Counting objects:  96% (50/52)\u001b[K\rremote: Counting objects:  98% (51/52)\u001b[K\rremote: Counting objects: 100% (52/52)\u001b[K\rremote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 19953 (delta 24), reused 29 (delta 8), pack-reused 19901\u001b[K\n",
            "Receiving objects: 100% (19953/19953), 11.99 MiB | 13.51 MiB/s, done.\n",
            "Resolving deltas: 100% (14486/14486), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZMJ0zMxDIyc",
        "colab_type": "text"
      },
      "source": [
        "## Run training using the run_language_modeling.py examples script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kvkxHIk2Vgn",
        "colab_type": "code",
        "outputId": "d5d27a25-1c51-4357-d759-c22cf6cb2266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "!nvidia-smi #just to confirm that you are on a GPU, if not go to Runtime->Change Runtime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Feb 22 15:58:32 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk2MUnKFV58z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting environment variables\n",
        "os.environ[\"train_path\"] = train_path\n",
        "os.environ[\"eval_path\"] = eval_path\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"]='1'  #Makes for easier debugging (just in case)\n",
        "weights_dir = \"/content/models/smallBERTa/weights\"\n",
        "!mkdir {weights_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UJ_BSAlmccq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cmd = '''python /content/transformers/examples/run_language_modeling.py --output_dir {0}  \\\n",
        "    --model_type roberta \\\n",
        "    --mlm \\\n",
        "    --train_data_file {1} \\\n",
        "    --eval_data_file {2} \\\n",
        "    --config_name /content/models/smallBERTa \\\n",
        "    --tokenizer_name /content/models/smallBERTa \\\n",
        "    --do_train \\\n",
        "    --line_by_line \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_eval \\\n",
        "    --block_size 256 \\\n",
        "    --learning_rate 1e-4 \\\n",
        "    --num_train_epochs 5 \\\n",
        "    --save_total_limit 2 \\\n",
        "    --save_steps 2000 \\\n",
        "    --logging_steps 500 \\\n",
        "    --per_gpu_eval_batch_size 32 \\\n",
        "    --per_gpu_train_batch_size 32 \\\n",
        "    --evaluate_during_training \\\n",
        "    --seed 42 \\\n",
        "    '''.format(weights_dir, train_path, eval_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqhJzq03Fc15",
        "colab_type": "code",
        "outputId": "89377d1e-d29e-4aa9-ef38-e70194a966ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!{cmd}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/22/2020 15:58:45 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "02/22/2020 15:58:45 - INFO - transformers.configuration_utils -   loading configuration file /content/models/smallBERTa/config.json\n",
            "02/22/2020 15:58:45 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
            "  \"architectures\": null,\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.3,\n",
            "  \"hidden_size\": 128,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 256,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 256,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 1,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 20000\n",
            "}\n",
            "\n",
            "02/22/2020 15:58:45 - INFO - transformers.tokenization_utils -   Model name '/content/models/smallBERTa' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming '/content/models/smallBERTa' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "02/22/2020 15:58:45 - INFO - transformers.tokenization_utils -   Didn't find file /content/models/smallBERTa/added_tokens.json. We won't load it.\n",
            "02/22/2020 15:58:45 - INFO - transformers.tokenization_utils -   Didn't find file /content/models/smallBERTa/special_tokens_map.json. We won't load it.\n",
            "02/22/2020 15:58:45 - INFO - transformers.tokenization_utils -   Didn't find file /content/models/smallBERTa/tokenizer_config.json. We won't load it.\n",
            "02/22/2020 15:58:45 - INFO - transformers.tokenization_utils -   loading file /content/models/smallBERTa/vocab.json\n",
            "02/22/2020 15:58:45 - INFO - transformers.tokenization_utils -   loading file /content/models/smallBERTa/merges.txt\n",
            "02/22/2020 15:58:45 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/22/2020 15:58:45 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/22/2020 15:58:45 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/22/2020 15:58:45 - INFO - __main__ -   Training new model from scratch\n",
            "02/22/2020 15:58:54 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=256, cache_dir=None, config_name='/content/models/smallBERTa', device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='/tmp/lm_data/eval.txt', evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=0.0001, line_by_line=True, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path=None, model_type='roberta', n_gpu=1, no_cuda=False, num_train_epochs=5.0, output_dir='/content/models/smallBERTa/weights', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=32, per_gpu_train_batch_size=32, save_steps=2000, save_total_limit=2, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name='/content/models/smallBERTa', train_data_file='/tmp/lm_data/train.txt', warmup_steps=0, weight_decay=0.0)\n",
            "02/22/2020 15:58:54 - INFO - __main__ -   Creating features from dataset file at /tmp/lm_data/train.txt\n",
            "02/22/2020 15:59:41 - INFO - __main__ -   ***** Running training *****\n",
            "02/22/2020 15:59:41 - INFO - __main__ -     Num examples = 276221\n",
            "02/22/2020 15:59:41 - INFO - __main__ -     Num Epochs = 5\n",
            "02/22/2020 15:59:41 - INFO - __main__ -     Instantaneous batch size per GPU = 32\n",
            "02/22/2020 15:59:41 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "02/22/2020 15:59:41 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "02/22/2020 15:59:41 - INFO - __main__ -     Total optimization steps = 43160\n",
            "Epoch:   0% 0/5 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/8632 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 1/8632 [00:00<1:04:06,  2.24it/s]\u001b[A\n",
            "Iteration:   0% 4/8632 [00:00<46:49,  3.07it/s]  \u001b[A\n",
            "Iteration:   0% 6/8632 [00:00<34:57,  4.11it/s]\u001b[A\n",
            "Iteration:   0% 8/8632 [00:00<26:55,  5.34it/s]\u001b[A\n",
            "Iteration:   0% 11/8632 [00:00<20:58,  6.85it/s]\u001b[A\n",
            "Iteration:   0% 13/8632 [00:01<17:05,  8.41it/s]\u001b[A\n",
            "Iteration:   0% 16/8632 [00:01<13:58, 10.28it/s]\u001b[A\n",
            "Iteration:   0% 18/8632 [00:01<12:12, 11.77it/s]\u001b[A\n",
            "Iteration:   0% 21/8632 [00:01<10:41, 13.43it/s]\u001b[A\n",
            "Iteration:   0% 23/8632 [00:01<09:41, 14.80it/s]\u001b[A\n",
            "Iteration:   0% 26/8632 [00:01<08:30, 16.84it/s]\u001b[A\n",
            "Iteration:   0% 29/8632 [00:01<08:20, 17.18it/s]\u001b[A\n",
            "Iteration:   0% 31/8632 [00:01<08:10, 17.55it/s]\u001b[A\n",
            "Iteration:   0% 33/8632 [00:02<08:16, 17.32it/s]\u001b[A\n",
            "Iteration:   0% 35/8632 [00:02<08:04, 17.73it/s]\u001b[A\n",
            "Iteration:   0% 38/8632 [00:02<07:35, 18.88it/s]\u001b[A\n",
            "Iteration:   0% 41/8632 [00:02<07:23, 19.38it/s]\u001b[A\n",
            "Iteration:   1% 44/8632 [00:02<07:18, 19.58it/s]\u001b[A\n",
            "Iteration:   1% 47/8632 [00:02<07:13, 19.80it/s]\u001b[A\n",
            "Iteration:   1% 50/8632 [00:02<07:06, 20.11it/s]\u001b[A\n",
            "Iteration:   1% 53/8632 [00:03<07:14, 19.75it/s]\u001b[A\n",
            "Iteration:   1% 56/8632 [00:03<07:07, 20.06it/s]\u001b[A\n",
            "Iteration:   1% 59/8632 [00:03<07:25, 19.24it/s]\u001b[A\n",
            "Iteration:   1% 61/8632 [00:03<07:22, 19.37it/s]\u001b[A\n",
            "Iteration:   1% 63/8632 [00:03<07:29, 19.08it/s]\u001b[A\n",
            "Iteration:   1% 66/8632 [00:03<07:18, 19.55it/s]\u001b[A\n",
            "Iteration:   1% 68/8632 [00:03<07:16, 19.61it/s]\u001b[A\n",
            "Iteration:   1% 70/8632 [00:03<07:27, 19.12it/s]\u001b[A\n",
            "Iteration:   1% 72/8632 [00:04<07:28, 19.10it/s]\u001b[A\n",
            "Iteration:   1% 74/8632 [00:04<07:23, 19.30it/s]\u001b[A\n",
            "Iteration:   1% 76/8632 [00:04<07:31, 18.94it/s]\u001b[A\n",
            "Iteration:   1% 79/8632 [00:04<07:27, 19.11it/s]\u001b[A\n",
            "Iteration:   1% 81/8632 [00:04<07:40, 18.55it/s]\u001b[A\n",
            "Iteration:   1% 83/8632 [00:04<07:33, 18.84it/s]\u001b[A\n",
            "Iteration:   1% 86/8632 [00:04<07:20, 19.41it/s]\u001b[A\n",
            "Iteration:   1% 88/8632 [00:04<07:38, 18.62it/s]\u001b[A\n",
            "Iteration:   1% 90/8632 [00:04<07:32, 18.86it/s]\u001b[A\n",
            "Iteration:   1% 92/8632 [00:05<07:54, 17.99it/s]\u001b[A\n",
            "Iteration:   1% 94/8632 [00:05<07:57, 17.88it/s]\u001b[A\n",
            "Iteration:   1% 96/8632 [00:05<07:57, 17.89it/s]\u001b[A\n",
            "Iteration:   1% 98/8632 [00:05<07:47, 18.27it/s]\u001b[A\n",
            "Iteration:   1% 100/8632 [00:05<07:37, 18.67it/s]\u001b[A\n",
            "Iteration:   1% 103/8632 [00:05<07:20, 19.36it/s]\u001b[A\n",
            "Iteration:   1% 105/8632 [00:05<07:19, 19.41it/s]\u001b[A\n",
            "Iteration:   1% 108/8632 [00:05<06:52, 20.69it/s]\u001b[A\n",
            "Iteration:   1% 111/8632 [00:06<06:39, 21.30it/s]\u001b[A\n",
            "Iteration:   1% 114/8632 [00:06<06:42, 21.15it/s]\u001b[A\n",
            "Iteration:   1% 117/8632 [00:06<06:54, 20.52it/s]\u001b[A\n",
            "Iteration:   1% 120/8632 [00:06<06:52, 20.65it/s]\u001b[A\n",
            "Iteration:   1% 123/8632 [00:06<06:46, 20.91it/s]\u001b[A\n",
            "Iteration:   1% 126/8632 [00:06<06:43, 21.10it/s]\u001b[A\n",
            "Iteration:   1% 129/8632 [00:06<06:58, 20.33it/s]\u001b[A\n",
            "Iteration:   2% 132/8632 [00:07<07:10, 19.76it/s]\u001b[A\n",
            "Iteration:   2% 134/8632 [00:07<07:10, 19.73it/s]\u001b[A\n",
            "Iteration:   2% 137/8632 [00:07<06:50, 20.67it/s]\u001b[A\n",
            "Iteration:   2% 140/8632 [00:07<06:43, 21.07it/s]\u001b[A\n",
            "Iteration:   2% 143/8632 [00:07<06:51, 20.64it/s]\u001b[A\n",
            "Iteration:   2% 146/8632 [00:07<06:46, 20.87it/s]\u001b[A\n",
            "Iteration:   2% 149/8632 [00:07<07:02, 20.07it/s]\u001b[A\n",
            "Iteration:   2% 152/8632 [00:08<09:37, 14.68it/s]\u001b[A\n",
            "Iteration:   2% 155/8632 [00:08<08:51, 15.95it/s]\u001b[A\n",
            "Iteration:   2% 157/8632 [00:08<08:42, 16.20it/s]\u001b[A\n",
            "Iteration:   2% 160/8632 [00:08<08:11, 17.25it/s]\u001b[A\n",
            "Iteration:   2% 163/8632 [00:08<07:38, 18.47it/s]\u001b[A\n",
            "Iteration:   2% 166/8632 [00:08<07:04, 19.94it/s]\u001b[A\n",
            "Iteration:   2% 169/8632 [00:09<07:03, 19.99it/s]\u001b[A\n",
            "Iteration:   2% 172/8632 [00:09<07:09, 19.69it/s]\u001b[A\n",
            "Iteration:   2% 175/8632 [00:09<07:04, 19.91it/s]\u001b[A\n",
            "Iteration:   2% 178/8632 [00:09<06:55, 20.35it/s]\u001b[A\n",
            "Iteration:   2% 181/8632 [00:09<06:53, 20.44it/s]\u001b[A\n",
            "Iteration:   2% 184/8632 [00:09<06:59, 20.15it/s]\u001b[A\n",
            "Iteration:   2% 187/8632 [00:09<07:07, 19.73it/s]\u001b[A\n",
            "Iteration:   2% 190/8632 [00:10<06:48, 20.67it/s]\u001b[A\n",
            "Iteration:   2% 193/8632 [00:10<06:56, 20.26it/s]\u001b[A\n",
            "Iteration:   2% 196/8632 [00:10<06:57, 20.22it/s]\u001b[A\n",
            "Iteration:   2% 199/8632 [00:10<06:58, 20.15it/s]\u001b[A\n",
            "Iteration:   2% 202/8632 [00:10<06:45, 20.77it/s]\u001b[A\n",
            "Iteration:   2% 205/8632 [00:10<06:34, 21.38it/s]\u001b[A\n",
            "Iteration:   2% 208/8632 [00:10<06:44, 20.83it/s]\u001b[A\n",
            "Iteration:   2% 211/8632 [00:11<06:50, 20.52it/s]\u001b[A\n",
            "Iteration:   2% 214/8632 [00:11<06:52, 20.41it/s]\u001b[A\n",
            "Iteration:   3% 217/8632 [00:11<06:51, 20.46it/s]\u001b[A\n",
            "Iteration:   3% 220/8632 [00:11<06:40, 21.01it/s]\u001b[A\n",
            "Iteration:   3% 223/8632 [00:11<06:51, 20.42it/s]\u001b[A\n",
            "Iteration:   3% 226/8632 [00:11<07:01, 19.93it/s]\u001b[A\n",
            "Iteration:   3% 229/8632 [00:12<06:54, 20.27it/s]\u001b[A\n",
            "Iteration:   3% 232/8632 [00:12<07:08, 19.59it/s]\u001b[A\n",
            "Iteration:   3% 234/8632 [00:12<07:52, 17.78it/s]\u001b[A\n",
            "Iteration:   3% 236/8632 [00:12<07:45, 18.03it/s]\u001b[A\n",
            "Iteration:   3% 238/8632 [00:12<07:32, 18.56it/s]\u001b[A\n",
            "Iteration:   3% 240/8632 [00:12<07:32, 18.53it/s]\u001b[A\n",
            "Iteration:   3% 243/8632 [00:12<07:10, 19.47it/s]\u001b[A\n",
            "Iteration:   3% 245/8632 [00:12<07:15, 19.26it/s]\u001b[A\n",
            "Iteration:   3% 247/8632 [00:12<07:18, 19.13it/s]\u001b[A\n",
            "Iteration:   3% 250/8632 [00:13<06:53, 20.28it/s]\u001b[A\n",
            "Iteration:   3% 253/8632 [00:13<06:49, 20.46it/s]\u001b[A\n",
            "Iteration:   3% 256/8632 [00:13<06:41, 20.85it/s]\u001b[A\n",
            "Iteration:   3% 259/8632 [00:13<06:36, 21.10it/s]\u001b[A\n",
            "Iteration:   3% 262/8632 [00:13<06:47, 20.52it/s]\u001b[A\n",
            "Iteration:   3% 265/8632 [00:13<07:09, 19.47it/s]\u001b[A\n",
            "Iteration:   3% 267/8632 [00:13<07:19, 19.04it/s]\u001b[A\n",
            "Iteration:   3% 269/8632 [00:14<07:21, 18.96it/s]\u001b[A\n",
            "Iteration:   3% 271/8632 [00:14<07:22, 18.88it/s]\u001b[A\n",
            "Iteration:   3% 273/8632 [00:14<07:22, 18.90it/s]\u001b[A\n",
            "Iteration:   3% 276/8632 [00:14<07:04, 19.69it/s]\u001b[A\n",
            "Iteration:   3% 278/8632 [00:14<07:03, 19.74it/s]\u001b[A\n",
            "Iteration:   3% 280/8632 [00:14<07:08, 19.49it/s]\u001b[A\n",
            "Iteration:   3% 283/8632 [00:14<06:49, 20.41it/s]\u001b[A\n",
            "Iteration:   3% 286/8632 [00:14<06:50, 20.32it/s]\u001b[A\n",
            "Iteration:   3% 289/8632 [00:15<06:45, 20.56it/s]\u001b[A\n",
            "Iteration:   3% 292/8632 [00:15<06:57, 19.98it/s]\u001b[A\n",
            "Iteration:   3% 295/8632 [00:15<07:01, 19.78it/s]\u001b[A\n",
            "Iteration:   3% 297/8632 [00:15<07:12, 19.25it/s]\u001b[A\n",
            "Iteration:   3% 300/8632 [00:15<07:05, 19.57it/s]\u001b[A\n",
            "Iteration:   4% 303/8632 [00:15<07:03, 19.67it/s]\u001b[A\n",
            "Iteration:   4% 306/8632 [00:15<07:00, 19.79it/s]\u001b[A\n",
            "Iteration:   4% 309/8632 [00:16<06:55, 20.04it/s]\u001b[A\n",
            "Iteration:   4% 312/8632 [00:16<06:49, 20.30it/s]\u001b[A\n",
            "Iteration:   4% 315/8632 [00:16<06:38, 20.85it/s]\u001b[A\n",
            "Iteration:   4% 318/8632 [00:16<07:04, 19.60it/s]\u001b[A\n",
            "Iteration:   4% 321/8632 [00:16<06:49, 20.30it/s]\u001b[A\n",
            "Iteration:   4% 324/8632 [00:16<06:46, 20.45it/s]\u001b[A\n",
            "Iteration:   4% 327/8632 [00:16<06:42, 20.64it/s]\u001b[A\n",
            "Iteration:   4% 330/8632 [00:17<06:38, 20.84it/s]\u001b[A\n",
            "Iteration:   4% 333/8632 [00:17<06:33, 21.10it/s]\u001b[A\n",
            "Iteration:   4% 336/8632 [00:17<06:32, 21.14it/s]\u001b[A\n",
            "Iteration:   4% 339/8632 [00:17<06:40, 20.72it/s]\u001b[A\n",
            "Iteration:   4% 342/8632 [00:17<06:44, 20.48it/s]\u001b[A\n",
            "Iteration:   4% 345/8632 [00:17<06:49, 20.24it/s]\u001b[A\n",
            "Iteration:   4% 348/8632 [00:17<06:43, 20.54it/s]\u001b[A\n",
            "Iteration:   4% 351/8632 [00:18<06:46, 20.40it/s]\u001b[A\n",
            "Iteration:   4% 354/8632 [00:18<06:49, 20.22it/s]\u001b[A\n",
            "Iteration:   4% 357/8632 [00:18<06:53, 20.00it/s]\u001b[A\n",
            "Iteration:   4% 360/8632 [00:18<06:52, 20.04it/s]\u001b[A\n",
            "Iteration:   4% 363/8632 [00:18<06:53, 19.98it/s]\u001b[A\n",
            "Iteration:   4% 365/8632 [00:18<06:57, 19.78it/s]\u001b[A\n",
            "Iteration:   4% 368/8632 [00:18<07:01, 19.59it/s]\u001b[A\n",
            "Iteration:   4% 371/8632 [00:19<06:57, 19.77it/s]\u001b[A\n",
            "Iteration:   4% 373/8632 [00:19<06:58, 19.72it/s]\u001b[A\n",
            "Iteration:   4% 375/8632 [00:19<06:59, 19.70it/s]\u001b[A\n",
            "Iteration:   4% 377/8632 [00:19<07:00, 19.64it/s]\u001b[A\n",
            "Iteration:   4% 379/8632 [00:19<07:06, 19.34it/s]\u001b[A\n",
            "Iteration:   4% 382/8632 [00:19<06:53, 19.95it/s]\u001b[A\n",
            "Iteration:   4% 385/8632 [00:19<06:48, 20.18it/s]\u001b[A\n",
            "Iteration:   4% 388/8632 [00:19<06:40, 20.57it/s]\u001b[A\n",
            "Iteration:   5% 391/8632 [00:20<06:46, 20.29it/s]\u001b[A\n",
            "Iteration:   5% 394/8632 [00:20<06:40, 20.59it/s]\u001b[A\n",
            "Iteration:   5% 397/8632 [00:20<06:38, 20.69it/s]\u001b[A\n",
            "Iteration:   5% 400/8632 [00:20<06:42, 20.44it/s]\u001b[A\n",
            "Iteration:   5% 403/8632 [00:20<06:36, 20.75it/s]\u001b[A\n",
            "Iteration:   5% 406/8632 [00:20<06:43, 20.41it/s]\u001b[A\n",
            "Iteration:   5% 409/8632 [00:20<06:46, 20.21it/s]\u001b[A\n",
            "Iteration:   5% 412/8632 [00:21<06:52, 19.91it/s]\u001b[A\n",
            "Iteration:   5% 415/8632 [00:21<06:43, 20.35it/s]\u001b[A\n",
            "Iteration:   5% 418/8632 [00:21<06:42, 20.40it/s]\u001b[A\n",
            "Iteration:   5% 421/8632 [00:21<06:47, 20.14it/s]\u001b[A\n",
            "Iteration:   5% 424/8632 [00:21<06:47, 20.12it/s]\u001b[A\n",
            "Iteration:   5% 427/8632 [00:21<07:02, 19.41it/s]\u001b[A\n",
            "Iteration:   5% 430/8632 [00:22<06:49, 20.02it/s]\u001b[A\n",
            "Iteration:   5% 433/8632 [00:22<06:52, 19.87it/s]\u001b[A\n",
            "Iteration:   5% 436/8632 [00:22<06:52, 19.89it/s]\u001b[A\n",
            "Iteration:   5% 438/8632 [00:22<07:04, 19.32it/s]\u001b[A\n",
            "Iteration:   5% 440/8632 [00:22<07:02, 19.41it/s]\u001b[A\n",
            "Iteration:   5% 442/8632 [00:22<07:03, 19.32it/s]\u001b[A\n",
            "Iteration:   5% 444/8632 [00:22<07:00, 19.47it/s]\u001b[A\n",
            "Iteration:   5% 447/8632 [00:22<07:06, 19.19it/s]\u001b[A\n",
            "Iteration:   5% 449/8632 [00:23<07:06, 19.21it/s]\u001b[A\n",
            "Iteration:   5% 451/8632 [00:23<07:08, 19.11it/s]\u001b[A\n",
            "Iteration:   5% 454/8632 [00:23<07:02, 19.37it/s]\u001b[A\n",
            "Iteration:   5% 457/8632 [00:23<06:54, 19.70it/s]\u001b[A\n",
            "Iteration:   5% 460/8632 [00:23<06:49, 19.98it/s]\u001b[A\n",
            "Iteration:   5% 463/8632 [00:23<06:50, 19.92it/s]\u001b[A\n",
            "Iteration:   5% 466/8632 [00:23<06:50, 19.89it/s]\u001b[A\n",
            "Iteration:   5% 469/8632 [00:24<06:50, 19.88it/s]\u001b[A\n",
            "Iteration:   5% 472/8632 [00:24<06:28, 20.99it/s]\u001b[A\n",
            "Iteration:   6% 475/8632 [00:24<06:23, 21.25it/s]\u001b[A\n",
            "Iteration:   6% 478/8632 [00:24<06:35, 20.62it/s]\u001b[A\n",
            "Iteration:   6% 481/8632 [00:24<06:48, 19.96it/s]\u001b[A\n",
            "Iteration:   6% 484/8632 [00:24<06:44, 20.12it/s]\u001b[A\n",
            "Iteration:   6% 487/8632 [00:24<06:38, 20.43it/s]\u001b[A\n",
            "Iteration:   6% 490/8632 [00:25<06:25, 21.11it/s]\u001b[A\n",
            "Iteration:   6% 493/8632 [00:25<06:22, 21.25it/s]\u001b[A\n",
            "Iteration:   6% 496/8632 [00:25<06:24, 21.15it/s]\u001b[A\n",
            "Iteration:   6% 499/8632 [00:25<06:33, 20.69it/s]\u001b[A02/22/2020 16:00:07 - INFO - __main__ -   Creating features from dataset file at /tmp/lm_data/eval.txt\n",
            "02/22/2020 16:00:12 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "02/22/2020 16:00:12 - INFO - __main__ -     Num examples = 30705\n",
            "02/22/2020 16:00:12 - INFO - __main__ -     Batch size = 32\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/960 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   1% 5/960 [00:00<00:20, 46.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   1% 10/960 [00:00<00:20, 45.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   2% 15/960 [00:00<00:21, 44.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   2% 20/960 [00:00<00:20, 45.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   3% 25/960 [00:00<00:20, 46.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   3% 31/960 [00:00<00:19, 47.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   4% 36/960 [00:00<00:19, 46.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   4% 41/960 [00:00<00:19, 46.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   5% 46/960 [00:00<00:19, 46.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   5% 51/960 [00:01<00:20, 45.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   6% 56/960 [00:01<00:19, 45.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   6% 61/960 [00:01<00:19, 45.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   7% 66/960 [00:01<00:19, 44.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   8% 72/960 [00:01<00:18, 47.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   8% 77/960 [00:01<00:18, 46.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   9% 82/960 [00:01<00:18, 46.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:   9% 87/960 [00:01<00:18, 47.31it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  10% 92/960 [00:01<00:18, 47.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  10% 97/960 [00:02<00:18, 47.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  11% 102/960 [00:02<00:18, 46.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  11% 107/960 [00:02<00:18, 46.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  12% 112/960 [00:02<00:18, 46.90it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  12% 118/960 [00:02<00:17, 47.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  13% 123/960 [00:02<00:17, 47.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  13% 128/960 [00:02<00:17, 46.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  14% 133/960 [00:02<00:17, 46.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  14% 138/960 [00:02<00:17, 46.16it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  15% 143/960 [00:03<00:17, 46.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  15% 148/960 [00:03<00:17, 46.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  16% 153/960 [00:03<00:17, 46.43it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  16% 158/960 [00:03<00:17, 46.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  17% 163/960 [00:03<00:17, 46.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  18% 168/960 [00:03<00:17, 46.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  18% 173/960 [00:03<00:17, 46.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  19% 178/960 [00:03<00:16, 46.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  19% 183/960 [00:03<00:16, 46.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  20% 188/960 [00:04<00:16, 46.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  20% 194/960 [00:04<00:15, 48.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  21% 199/960 [00:04<00:15, 48.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  21% 204/960 [00:04<00:15, 48.29it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  22% 209/960 [00:04<00:15, 47.34it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  22% 214/960 [00:04<00:15, 47.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  23% 220/960 [00:04<00:15, 48.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  23% 225/960 [00:04<00:15, 48.35it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  24% 230/960 [00:04<00:15, 47.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 236/960 [00:05<00:15, 47.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  25% 241/960 [00:05<00:15, 47.12it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  26% 246/960 [00:05<00:14, 47.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  26% 251/960 [00:05<00:14, 47.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  27% 256/960 [00:05<00:14, 47.53it/s]\u001b[A\u001b[A"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSh-tXR8MPd6",
        "colab_type": "text"
      },
      "source": [
        "## Run Fill Mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XARiguDMSdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"/content/models/tinyBERT/weights/checkpoint-36000\",\n",
        "    tokenizer=\"/content/models/tinyBERT/weights/checkpoint-36000\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx-8gQwBMUCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = fill_mask(\"aaj bahot <mask> ho raha hei\")\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pirlhhohke8T",
        "colab_type": "text"
      },
      "source": [
        "## View Results on Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siSNrtODEqUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorboard dev upload --logdir /content/runs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}